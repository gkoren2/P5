{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA on preprocessed data\n",
    "code was taken from `test_beauty_small.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "os.chdir('../')\n",
    "\n",
    "import collections\n",
    "import random\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import shutil\n",
    "import time\n",
    "from packaging import version\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gzip\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from src.param import parse_args\n",
    "from src.utils import LossMeter\n",
    "from src.dist_utils import reduce_dict\n",
    "from transformers import T5Tokenizer, T5TokenizerFast\n",
    "from src.tokenization import P5Tokenizer, P5TokenizerFast\n",
    "from src.pretrain_model import P5Pretraining\n",
    "\n",
    "_use_native_amp = False\n",
    "_use_apex = False\n",
    "\n",
    "# Check if Pytorch version >= 1.6 to switch between Native AMP and Apex\n",
    "if version.parse(torch.__version__) < version.parse(\"1.6\"):\n",
    "    from transormers.file_utils import is_apex_available\n",
    "    if is_apex_available():\n",
    "        from apex import amp\n",
    "    _use_apex = True\n",
    "else:\n",
    "    _use_native_amp = True\n",
    "    from torch.cuda.amp import autocast\n",
    "\n",
    "from src.trainer_base import TrainerBase\n",
    "\n",
    "import pickle\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def save_pickle(data, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "import json\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def ReadLineFromFile(path):\n",
    "    lines = []\n",
    "    with open(path,'r') as fd:\n",
    "        for line in fd:\n",
    "            lines.append(line.rstrip('\\n'))\n",
    "    return lines\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_meta_data(dataset_root, meta_file_name):\n",
    "    meta_file_name = os.path.join(dataset_root,meta_file_name)\n",
    "    cached_filename = os.path.join(dataset_root,os.path.basename(meta_file_name).split('.json')[0]+'.csv')\n",
    "    if os.path.exists(cached_filename):\n",
    "        print(f'loading from cached file {cached_filename}')\n",
    "        df=pd.read_csv(cached_filename)\n",
    "    else:\n",
    "        data=[]\n",
    "        with gzip.open(meta_file_name) as f:\n",
    "            for l in tqdm(f):\n",
    "                data.append(json.loads(l.strip()))\n",
    "        df = pd.DataFrame.from_dict(data)\n",
    "        df.to_csv(cached_filename,index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_meta_data(meta_file, data_maps):\n",
    "    datas={}\n",
    "    item_asins = list(data_maps['item2id'].keys())\n",
    "    for info in parse(meta_file):\n",
    "        if info['asin'] not in item_asins:\n",
    "            continue\n",
    "        datas[info['asin']] = info\n",
    "    return datas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "├── P5_data.zip\n",
      "├── beauty\n",
      "│   ├── datamaps.json\n",
      "│   ├── exp_splits.pkl\n",
      "│   ├── meta.json.gz\n",
      "│   ├── negative_samples.txt\n",
      "│   ├── rating_splits_augmented.pkl\n",
      "│   ├── review_splits.pkl\n",
      "│   ├── sequential_data.txt\n",
      "│   ├── user_id2name.pkl\n",
      "│   └── zeroshot_exp_splits.pkl\n",
      "├── sports\n",
      "│   ├── datamaps.json\n",
      "│   ├── exp_splits.pkl\n",
      "│   ├── meta.json.gz\n",
      "│   ├── negative_samples.txt\n",
      "│   ├── rating_splits_augmented.pkl\n",
      "│   ├── review_splits.pkl\n",
      "│   ├── sequential_data.txt\n",
      "│   ├── user_id2name.pkl\n",
      "│   └── zeroshot_exp_splits.pkl\n",
      "├── toys\n",
      "│   ├── datamaps.json\n",
      "│   ├── exp_splits.pkl\n",
      "│   ├── meta.json.gz\n",
      "│   ├── negative_samples.txt\n",
      "│   ├── rating_splits_augmented.pkl\n",
      "│   ├── review_splits.pkl\n",
      "│   ├── sequential_data.txt\n",
      "│   ├── user_id2name.pkl\n",
      "│   └── zeroshot_exp_splits.pkl\n",
      "└── yelp\n",
      "    ├── datamaps.json\n",
      "    ├── exp_splits.pkl\n",
      "    ├── meta_data.pkl\n",
      "    ├── negative_samples.txt\n",
      "    ├── rating_splits_augmented.pkl\n",
      "    ├── review_splits.pkl\n",
      "    ├── sequential_data.txt\n",
      "    ├── user_data.pkl\n",
      "    └── user_id2name.pkl\n",
      "\n",
      "4 directories, 37 files\n"
     ]
    }
   ],
   "source": [
    "!tree data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22363\n",
      "12101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['user2id', 'item2id', 'id2user', 'id2item', 'attribute2id', 'id2attribute', 'attributeid2num'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_maps_beauty = load_json(os.path.join('data', 'beauty', 'datamaps.json'))\n",
    "print(len(data_maps_beauty['user2id'])) # number of users\n",
    "print(len(data_maps_beauty['item2id'])) # number of items\n",
    "data_maps_beauty.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train: 106281, val: 13515, test: 13421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'reviewerID': 'A3G6XNM240RMWA',\n",
       " 'asin': '7806397051',\n",
       " 'reviewerName': 'Karen',\n",
       " 'helpful': [0, 1],\n",
       " 'reviewText': \"The texture of this concealer pallet is fantastic, it has great coverage and a wide variety of uses, I guess it's meant for professional makeup artists and a lot of the colours are of no use to me but I use at least two of them on a regular basis, and two more occasionally, which is the only reason I'm giving it for stars, I feel like the range of colors is kind of a waste for me, but the  product itself  is wonderful, it's not cakey, gives me a natural for and concealed my imperfections, therefore I highly recommend it :)\",\n",
       " 'overall': 4.0,\n",
       " 'summary': 'great quality',\n",
       " 'unixReviewTime': 1378425600,\n",
       " 'reviewTime': '09 6, 2013',\n",
       " 'explanation': 'great quality',\n",
       " 'feature': 'quality'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_splits = load_pickle('data/beauty/exp_splits.pkl')\n",
    "print (f\" train: {len(exp_splits['train'])}, val: {len(exp_splits['val'])}, test: {len(exp_splits['test'])}\")\n",
    "exp_splits['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'asin': '7806397051',\n",
       " 'related': {'also_bought': ['B00KR26VFE',\n",
       "   'B00E7LQHZ0',\n",
       "   'B00BMW24TU',\n",
       "   'B00K67AQN8',\n",
       "   'B008GOR6O0',\n",
       "   'B00KVBZAXK',\n",
       "   'B008B2Z94Q',\n",
       "   'B00IIFVJZ4',\n",
       "   'B00FYUX3Z0',\n",
       "   'B00HWR1OZ4',\n",
       "   'B00EYZR3E8',\n",
       "   'B00IHQKRCA',\n",
       "   'B00KS4FDLO',\n",
       "   'B00GBTX1GO',\n",
       "   'B00FYVOG1Y',\n",
       "   'B009WJCEMM',\n",
       "   'B00ID5PRQQ',\n",
       "   'B00IIG7UQ0',\n",
       "   'B0068Y0EXK',\n",
       "   'B00JFLRCOW',\n",
       "   'B009NAE91E',\n",
       "   'B00B4YVU4G',\n",
       "   'B00K48JDWY',\n",
       "   'B006HCJXBM',\n",
       "   'B009VXY05S',\n",
       "   'B00I99OON8',\n",
       "   'B009WI3RZQ',\n",
       "   'B00IJ3LG94',\n",
       "   'B0067F8BBM',\n",
       "   'B002TPQPEE',\n",
       "   'B00IBVE79K',\n",
       "   'B00K05ZR08',\n",
       "   'B00K407VOO',\n",
       "   'B00GMDIKV0',\n",
       "   'B00KWSCOZO',\n",
       "   'B00EL1HZ34',\n",
       "   'B00HKA110G',\n",
       "   'B00KL53KGA',\n",
       "   'B00B8P5CTA',\n",
       "   'B00EYYW2HW',\n",
       "   'B00IKBGQAE',\n",
       "   'B00KHKXPHS',\n",
       "   'B00HPS4664',\n",
       "   'B00I9ZCV6E',\n",
       "   'B00EOFEKF8',\n",
       "   'B00F16KHLA',\n",
       "   'B00L0R8KK4',\n",
       "   'B00G8F2RNE',\n",
       "   'B00942W51C',\n",
       "   'B00KXOLTD0',\n",
       "   'B00DAYGJVW',\n",
       "   'B004X1QY20',\n",
       "   'B00BLDA3J8',\n",
       "   'B00HL9BG9C',\n",
       "   'B00GLM2FAO',\n",
       "   'B00JEGCI6U',\n",
       "   'B00K7P74GQ',\n",
       "   'B004W5RCNM',\n",
       "   'B00JK99BNE',\n",
       "   'B005TKZS76',\n",
       "   'B00E57MCMS',\n",
       "   'B001TK1I4M',\n",
       "   'B00CQ1DKZS',\n",
       "   'B00FORNVGO',\n",
       "   'B00GQU5YY0',\n",
       "   'B00GZIHP3G',\n",
       "   'B00BX7DGIC',\n",
       "   'B004GNMP0U',\n",
       "   'B00DQ2ILQY',\n",
       "   'B00IZZ7RTO',\n",
       "   'B00CBT0TYU',\n",
       "   'B008NQJA5E',\n",
       "   'B0092LDWVW',\n",
       "   'B00HQ8MA70',\n",
       "   'B003QAPTAW',\n",
       "   'B004M7WKKK',\n",
       "   'B00H1SW3RC',\n",
       "   'B008FX7B9M',\n",
       "   'B0061KQEVW',\n",
       "   'B00IIFOEIS',\n",
       "   'B006GTKSHY',\n",
       "   'B00D8U570W',\n",
       "   'B00IQK5K4C',\n",
       "   'B00IZ6KIE4',\n",
       "   'B00FORNYMU',\n",
       "   'B00LAYIFD4',\n",
       "   'B00ACOFN0Q',\n",
       "   'B00BZ4QDW4',\n",
       "   'B005C8MMPQ',\n",
       "   '1111306923',\n",
       "   'B006Z5K3FG',\n",
       "   'B0054SIB1S',\n",
       "   'B002UBVZYC',\n",
       "   'B00J921XM4',\n",
       "   'B00CZ4W8UE',\n",
       "   'B00EU89CKC',\n",
       "   'B00J3IFAA0',\n",
       "   'B005O30Q0M'],\n",
       "  'also_viewed': ['B008GOR6O0',\n",
       "   'B00EOFEKF8',\n",
       "   'B00IIFVJZ4',\n",
       "   'B009C7RZNC',\n",
       "   'B00K05ZR08',\n",
       "   'B009NAE9A0',\n",
       "   'B00A66T112',\n",
       "   'B00C8R39TM',\n",
       "   'B009VYF0MY',\n",
       "   'B00K0683R6',\n",
       "   'B004M7WKKK',\n",
       "   'B00K0683OE',\n",
       "   'B008MU8TL2',\n",
       "   'B00HKA110G',\n",
       "   'B00K0683PS',\n",
       "   'B00BMW24TU',\n",
       "   'B0061KQEVW',\n",
       "   'B00E7LQHZ0',\n",
       "   'B00KR26VFE',\n",
       "   'B00IHR9EVE',\n",
       "   'B00IHQKRCA',\n",
       "   'B00GWDKRG6',\n",
       "   'B00DFQOIJA',\n",
       "   'B00GWDZBHQ',\n",
       "   'B002QFGQAK',\n",
       "   'B007RKC27U',\n",
       "   'B00JE46HM8',\n",
       "   'B00IIG7UQ0',\n",
       "   'B009NAE91E',\n",
       "   'B008D5JRL2',\n",
       "   'B00IHR9EV4',\n",
       "   'B00CZ49RSK',\n",
       "   'B00J3HHJUA',\n",
       "   'B009WJCEMM',\n",
       "   'B004I3LU7C',\n",
       "   'B00LE9YL0G',\n",
       "   'B00EYZR3E8',\n",
       "   'B00FQ8OL6U',\n",
       "   'B00L54D9NU',\n",
       "   'B00GBTX1GO',\n",
       "   'B00I9GTBD4',\n",
       "   'B00IVHDGMS',\n",
       "   'B009P732GI',\n",
       "   'B008B2Z94Q',\n",
       "   'B004UO2GMW',\n",
       "   'B00KHOF6V2',\n",
       "   'B008D5D9NY',\n",
       "   'B00IHQQGKM',\n",
       "   'B00AU05YVU',\n",
       "   'B00HWR1OZ4',\n",
       "   'B00K67AQN8',\n",
       "   'B002QFGKUQ',\n",
       "   'B0067F8BBM',\n",
       "   'B00FYVOG1Y'],\n",
       "  'bought_together': ['B008GOR6O0']},\n",
       " 'title': 'WAWO 15 Color Professionl Makeup Eyeshadow Camouflage Facial Concealer Neutral Palette',\n",
       " 'price': 5.04,\n",
       " 'salesRank': {'Beauty': 10486},\n",
       " 'imUrl': 'http://ecx.images-amazon.com/images/I/41Rn18OeU6L._SY300_.jpg',\n",
       " 'brand': 'COKA',\n",
       " 'categories': [['Beauty', 'Makeup', 'Face', 'Concealers & Neutralizers']],\n",
       " 'description': 'An extensive range of 15 multiple vibrant long wear concealer colour with different skin tones to create more than 10,000 amazing looks. Using the most commonly applied shades, ensures the best skin colour match and guarantees a traceless and natural finish. Enabling layering and mixing, provides total camouflage for almost any skin problem including blemishes, scars, birthmarks and black circles. It is also suitable to use as bronzer. The light colour is suitable for redness, acne and so on. The medium colour is perfect for dark shadows in the under-eye area. The dark colour provides exceptional camouflage and adheres well to the skin. Silky glossy colour and high quality ingredients together to care skin around and can last for all day long. It is perfect for Professional Salon, Wedding, Party and Home use. Size: 15.4 x 10.2 x 1.3cm. Each Diameter: 2.6cm. Concealer: 15 Color Concealer.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it looks like item data. the length is the number of items\n",
    "datas = read_meta_data('data/beauty/meta.json.gz',data_maps_beauty)\n",
    "print(len(datas))\n",
    "datas['7806397051']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'val', 'test', 'train_indices', 'val_indices', 'test_indices'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_splits = load_pickle('data/beauty/rating_splits_augmented.pkl')\n",
    "test_review_data = data_splits['test']\n",
    "data_splits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train: 317516, val: 19850, test: 19850\n",
      " train: 158802, val: 19850, test: 19850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (f\" train: {len(data_splits['train'])}, val: {len(data_splits['val'])}, test: {len(data_splits['test'])}\")\n",
    "# what is the indices ? why in train I have less indices than train data ?\n",
    "# the total number of indices = the number of actions as reported in the paper. these are the actual transactions\n",
    "print (f\" train: {len(data_splits['train_indices'])}, val: {len(data_splits['val_indices'])}, test: {len(data_splits['test_indices'])}\")\n",
    "data_splits['train_indices'][120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_review_data))\n",
    "test_review_data[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19412\n",
      "11924\n"
     ]
    }
   ],
   "source": [
    "data_maps_toys = load_json(os.path.join('data', 'toys', 'datamaps.json'))\n",
    "print(len(data_maps_toys['user2id'])) # number of users\n",
    "print(len(data_maps_toys['item2id'])) # number of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35598\n",
      "18357\n"
     ]
    }
   ],
   "source": [
    "data_maps_sports = load_json(os.path.join('data', 'sports', 'datamaps.json'))\n",
    "print(len(data_maps_sports['user2id'])) # number of users\n",
    "print(len(data_maps_sports['item2id'])) # number of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19412 22363 35598 2073 1734 1625\n"
     ]
    }
   ],
   "source": [
    "toys_uids = set(data_maps_toys['user2id'].keys())\n",
    "beauty_uids = set(data_maps_beauty['user2id'].keys())\n",
    "sports_uids = set(data_maps_sports['user2id'].keys())\n",
    "\n",
    "# find intersection between toys_uids and beauty_uids\n",
    "toys_beauty_int = toys_uids.intersection(beauty_uids)\n",
    "toys_sports_int = toys_uids.intersection(sports_uids)\n",
    "beauty_sports_int = beauty_uids.intersection(sports_uids)\n",
    "\n",
    "print(len(toys_uids),len(beauty_uids), len(sports_uids),len(toys_beauty_int),len(toys_sports_int),len(beauty_sports_int))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so there's an overlap in user ids. not too big, but exist. probably the same users. where do I get the user description from ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zsexp_splits = load_pickle('data/beauty/zeroshot_exp_splits.pkl')\n",
    "# print (f\" train: {len(zsexp_splits['train'])}, val: {len(zsexp_splits['val'])}, test: {len(zsexp_splits['test'])}\")\n",
    "len(zsexp_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_splits = load_pickle('data/beauty/review_splits.pkl')\n",
    "print (f\" train: {len(rev_splits['train'])}, val: {len(rev_splits['val'])}, test: {len(rev_splits['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_splits['train'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits['train'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid2name = load_pickle('data/beauty/user_id2name.pkl')\n",
    "uid2name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "taken from the preprocessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def save_pickle(data, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def ReadLineFromFile(path):\n",
    "    lines = []\n",
    "    with open(path,'r') as fd:\n",
    "        for line in fd:\n",
    "            lines.append(line.rstrip('\\n'))\n",
    "    return lines\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "        \n",
    "'''\n",
    "Set seeds\n",
    "'''\n",
    "seed = 2022\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_data_name = 'beauty'\n",
    "os.mkdir(short_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if short_data_name == 'beauty':\n",
    "    full_data_name = 'Beauty'\n",
    "elif short_data_name == 'toys':\n",
    "    full_data_name = 'Toys_and_Games'\n",
    "elif short_data_name == 'sports':\n",
    "    full_data_name = 'Sports_and_Outdoors'\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Sequential Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return (user item timestamp) sort in get_interaction\n",
    "def Amazon(dataset_name, rating_score):\n",
    "    '''\n",
    "    reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "    asin - ID of the product, e.g. 0000013714\n",
    "    reviewerName - name of the reviewer\n",
    "    helpful - helpfulness rating of the review, e.g. 2/3\n",
    "    --\"helpful\": [2, 3],\n",
    "    reviewText - text of the review\n",
    "    --\"reviewText\": \"I bought this for my husband who plays the piano. ...\"\n",
    "    overall - rating of the product\n",
    "    --\"overall\": 5.0,\n",
    "    summary - summary of the review\n",
    "    --\"summary\": \"Heavenly Highway Hymns\",\n",
    "    unixReviewTime - time of the review (unix time)\n",
    "    --\"unixReviewTime\": 1252800000,\n",
    "    reviewTime - time of the review (raw)\n",
    "    --\"reviewTime\": \"09 13, 2009\"\n",
    "    '''\n",
    "    datas = []\n",
    "    # older Amazon\n",
    "    data_file = './raw_data/reviews_' + dataset_name + '.json.gz'\n",
    "    # latest Amazon\n",
    "    # data_file = '/home/hui_wang/data/new_Amazon/' + dataset_name + '.json.gz'\n",
    "    for inter in parse(data_file):\n",
    "        if float(inter['overall']) <= rating_score: # 小于一定分数去掉\n",
    "            continue\n",
    "        user = inter['reviewerID']\n",
    "        item = inter['asin']\n",
    "        time = inter['unixReviewTime']\n",
    "        datas.append((user, item, int(time)))\n",
    "    return datas\n",
    "\n",
    "def Amazon_meta(dataset_name, data_maps):\n",
    "    '''\n",
    "    asin - ID of the product, e.g. 0000031852\n",
    "    --\"asin\": \"0000031852\",\n",
    "    title - name of the product\n",
    "    --\"title\": \"Girls Ballet Tutu Zebra Hot Pink\",\n",
    "    description\n",
    "    price - price in US dollars (at time of crawl)\n",
    "    --\"price\": 3.17,\n",
    "    imUrl - url of the product image (str)\n",
    "    --\"imUrl\": \"http://ecx.images-amazon.com/images/I/51fAmVkTbyL._SY300_.jpg\",\n",
    "    related - related products (also bought, also viewed, bought together, buy after viewing)\n",
    "    --\"related\":{\n",
    "        \"also_bought\": [\"B00JHONN1S\"],\n",
    "        \"also_viewed\": [\"B002BZX8Z6\"],\n",
    "        \"bought_together\": [\"B002BZX8Z6\"]\n",
    "    },\n",
    "    salesRank - sales rank information\n",
    "    --\"salesRank\": {\"Toys & Games\": 211836}\n",
    "    brand - brand name\n",
    "    --\"brand\": \"Coxlures\",\n",
    "    categories - list of categories the product belongs to\n",
    "    --\"categories\": [[\"Sports & Outdoors\", \"Other Sports\", \"Dance\"]]\n",
    "    '''\n",
    "    datas = {}\n",
    "    meta_file = './raw_data/meta_' + dataset_name + '.json.gz'\n",
    "    item_asins = list(data_maps['item2id'].keys())\n",
    "    for info in parse(meta_file):\n",
    "        if info['asin'] not in item_asins:\n",
    "            continue\n",
    "        datas[info['asin']] = info\n",
    "    return datas\n",
    "\n",
    "def add_comma(num):\n",
    "    # 1000000 -> 1,000,000\n",
    "    str_num = str(num)\n",
    "    res_num = ''\n",
    "    for i in range(len(str_num)):\n",
    "        res_num += str_num[i]\n",
    "        if (len(str_num)-i-1) % 3 == 0:\n",
    "            res_num += ','\n",
    "    return res_num[:-1]\n",
    "\n",
    "# categories 和 brand is all attribute\n",
    "def get_attribute_Amazon(meta_infos, datamaps, attribute_core):\n",
    "\n",
    "    attributes = defaultdict(int)\n",
    "    for iid, info in tqdm(meta_infos.items()):\n",
    "        for cates in info['categories']:\n",
    "            for cate in cates[1:]: # 把主类删除 没有用\n",
    "                attributes[cate] +=1\n",
    "        try:\n",
    "            attributes[info['brand']] += 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    print(f'before delete, attribute num:{len(attributes)}')\n",
    "    new_meta = {}\n",
    "    for iid, info in tqdm(meta_infos.items()):\n",
    "        new_meta[iid] = []\n",
    "\n",
    "        try:\n",
    "            if attributes[info['brand']] >= attribute_core:\n",
    "                new_meta[iid].append(info['brand'])\n",
    "        except:\n",
    "            pass\n",
    "        for cates in info['categories']:\n",
    "            for cate in cates[1:]:\n",
    "                if attributes[cate] >= attribute_core:\n",
    "                    new_meta[iid].append(cate)\n",
    "    # 做映射\n",
    "    attribute2id = {}\n",
    "    id2attribute = {}\n",
    "    attributeid2num = defaultdict(int)\n",
    "    attribute_id = 1\n",
    "    items2attributes = {}\n",
    "    attribute_lens = []\n",
    "\n",
    "    for iid, attributes in new_meta.items():\n",
    "        item_id = datamaps['item2id'][iid]\n",
    "        items2attributes[item_id] = []\n",
    "        for attribute in attributes:\n",
    "            if attribute not in attribute2id:\n",
    "                attribute2id[attribute] = attribute_id\n",
    "                id2attribute[attribute_id] = attribute\n",
    "                attribute_id += 1\n",
    "            attributeid2num[attribute2id[attribute]] += 1\n",
    "            items2attributes[item_id].append(attribute2id[attribute])\n",
    "        attribute_lens.append(len(items2attributes[item_id]))\n",
    "    print(f'before delete, attribute num:{len(attribute2id)}')\n",
    "    print(f'attributes len, Min:{np.min(attribute_lens)}, Max:{np.max(attribute_lens)}, Avg.:{np.mean(attribute_lens):.4f}')\n",
    "    # 更新datamap\n",
    "    datamaps['attribute2id'] = attribute2id\n",
    "    datamaps['id2attribute'] = id2attribute\n",
    "    datamaps['attributeid2num'] = attributeid2num\n",
    "    return len(attribute2id), np.mean(attribute_lens), datamaps, items2attributes\n",
    "\n",
    "\n",
    "def get_interaction(datas):\n",
    "    user_seq = {}\n",
    "    for data in datas:\n",
    "        user, item, time = data\n",
    "        if user in user_seq:\n",
    "            user_seq[user].append((item, time))\n",
    "        else:\n",
    "            user_seq[user] = []\n",
    "            user_seq[user].append((item, time))\n",
    "\n",
    "    for user, item_time in user_seq.items():\n",
    "        item_time.sort(key=lambda x: x[1])  # sort each dataset individually\n",
    "        items = []\n",
    "        for t in item_time:\n",
    "            items.append(t[0])\n",
    "        user_seq[user] = items\n",
    "    return user_seq\n",
    "\n",
    "# K-core user_core item_core\n",
    "def check_Kcore(user_items, user_core, item_core):\n",
    "    user_count = defaultdict(int)\n",
    "    item_count = defaultdict(int)\n",
    "    for user, items in user_items.items():\n",
    "        for item in items:\n",
    "            user_count[user] += 1\n",
    "            item_count[item] += 1\n",
    "\n",
    "    for user, num in user_count.items():\n",
    "        if num < user_core:\n",
    "            return user_count, item_count, False\n",
    "    for item, num in item_count.items():\n",
    "        if num < item_core:\n",
    "            return user_count, item_count, False\n",
    "    return user_count, item_count, True # 已经保证Kcore\n",
    "\n",
    "# 循环过滤 K-core\n",
    "def filter_Kcore(user_items, user_core, item_core): # user 接所有items\n",
    "    user_count, item_count, isKcore = check_Kcore(user_items, user_core, item_core)\n",
    "    while not isKcore:\n",
    "        for user, num in user_count.items():\n",
    "            if user_count[user] < user_core: # 直接把user 删除\n",
    "                user_items.pop(user)\n",
    "            else:\n",
    "                for item in user_items[user]:\n",
    "                    if item_count[item] < item_core:\n",
    "                        user_items[user].remove(item)\n",
    "        user_count, item_count, isKcore = check_Kcore(user_items, user_core, item_core)\n",
    "    return user_items\n",
    "\n",
    "def id_map(user_items): # user_items dict\n",
    "    user2id = {} # raw 2 uid\n",
    "    item2id = {} # raw 2 iid\n",
    "    id2user = {} # uid 2 raw\n",
    "    id2item = {} # iid 2 raw\n",
    "    user_id = 1\n",
    "    item_id = 1\n",
    "    final_data = {}\n",
    "    random_user_list = list(user_items.keys())\n",
    "    random.shuffle(random_user_list)\n",
    "    for user in random_user_list:\n",
    "        items = user_items[user]\n",
    "        if user not in user2id:\n",
    "            user2id[user] = str(user_id)\n",
    "            id2user[str(user_id)] = user\n",
    "            user_id += 1\n",
    "        iids = [] # item id lists\n",
    "        for item in items:\n",
    "            if item not in item2id:\n",
    "                item2id[item] = str(item_id)\n",
    "                id2item[str(item_id)] = item\n",
    "                item_id += 1\n",
    "            iids.append(item2id[item])\n",
    "        uid = user2id[user]\n",
    "        final_data[uid] = iids\n",
    "    data_maps = {\n",
    "        'user2id': user2id,\n",
    "        'item2id': item2id,\n",
    "        'id2user': id2user,\n",
    "        'id2item': id2item\n",
    "    }\n",
    "    return final_data, user_id-1, item_id-1, data_maps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_name, acronym, data_type='Amazon'):\n",
    "    assert data_type in {'Amazon', 'Yelp'}\n",
    "    rating_score = 0.0  # rating score smaller than this score would be deleted\n",
    "    # user 5-core item 5-core\n",
    "    user_core = 5\n",
    "    item_core = 5\n",
    "    attribute_core = 0\n",
    "\n",
    "    if data_type == 'Yelp':\n",
    "        date_max = '2019-12-31 00:00:00'\n",
    "        date_min = '2019-01-01 00:00:00'\n",
    "        datas = Yelp(date_min, date_max, rating_score)\n",
    "    else:\n",
    "        datas = Amazon(data_name+'_5', rating_score=rating_score)\n",
    "\n",
    "    user_items = get_interaction(datas)\n",
    "    print(f'{data_name} Raw data has been processed! Lower than {rating_score} are deleted!')\n",
    "    # raw_id user: [item1, item2, item3...]\n",
    "    user_items = filter_Kcore(user_items, user_core=user_core, item_core=item_core)\n",
    "    print(f'User {user_core}-core complete! Item {item_core}-core complete!')\n",
    "\n",
    "    user_items, user_num, item_num, data_maps = id_map(user_items)\n",
    "    user_count, item_count, _ = check_Kcore(user_items, user_core=user_core, item_core=item_core)\n",
    "    user_count_list = list(user_count.values())\n",
    "    user_avg, user_min, user_max = np.mean(user_count_list), np.min(user_count_list), np.max(user_count_list)\n",
    "    item_count_list = list(item_count.values())\n",
    "    item_avg, item_min, item_max = np.mean(item_count_list), np.min(item_count_list), np.max(item_count_list)\n",
    "    interact_num = np.sum([x for x in user_count_list])\n",
    "    sparsity = (1 - interact_num / (user_num * item_num)) * 100\n",
    "    show_info = f'Total User: {user_num}, Avg User: {user_avg:.4f}, Min Len: {user_min}, Max Len: {user_max}\\n' + \\\n",
    "                f'Total Item: {item_num}, Avg Item: {item_avg:.4f}, Min Inter: {item_min}, Max Inter: {item_max}\\n' + \\\n",
    "                f'Iteraction Num: {interact_num}, Sparsity: {sparsity:.2f}%'\n",
    "    print(show_info)\n",
    "\n",
    "\n",
    "    print('Begin extracting meta infos...')\n",
    "\n",
    "    if data_type == 'Amazon':\n",
    "        meta_infos = Amazon_meta(data_name, data_maps)\n",
    "        attribute_num, avg_attribute, datamaps, item2attributes = get_attribute_Amazon(meta_infos, data_maps, attribute_core)\n",
    "    else:\n",
    "        meta_infos = Yelp_meta(data_maps)\n",
    "        attribute_num, avg_attribute, datamaps, item2attributes = get_attribute_Yelp(meta_infos, data_maps, attribute_core)\n",
    "\n",
    "    print(f'{data_name} & {add_comma(user_num)}& {add_comma(item_num)} & {user_avg:.1f}'\n",
    "          f'& {item_avg:.1f}& {add_comma(interact_num)}& {sparsity:.2f}\\%&{add_comma(attribute_num)}&'\n",
    "          f'{avg_attribute:.1f} \\\\')\n",
    "\n",
    "    # -------------- Save Data ---------------\n",
    "    data_file = './{}/'.format(acronym) + 'sequential_data.txt'\n",
    "    item2attributes_file = './{}/'.format(acronym) + 'item2attributes.json'\n",
    "    datamaps_file = './{}/'.format(acronym) + 'datamaps.json'\n",
    "\n",
    "    with open(data_file, 'w') as out:\n",
    "        for user, items in user_items.items():\n",
    "            out.write(user + ' ' + ' '.join(items) + '\\n')\n",
    "    json_str = json.dumps(item2attributes)\n",
    "    with open(item2attributes_file, 'w') as out:\n",
    "        out.write(json_str)\n",
    "        \n",
    "    json_str = json.dumps(datamaps)\n",
    "    with open(datamaps_file, 'w') as out:\n",
    "        out.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(full_data_name, short_data_name, data_type='Amazon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_test_data(data_name, test_num=99, sample_type='random'):\n",
    "    \"\"\"\n",
    "    sample_type:\n",
    "        random:  sample `test_num` negative items randomly.\n",
    "        pop: sample `test_num` negative items according to item popularity.\n",
    "    \"\"\"\n",
    "\n",
    "    data_file = f'sequential_data.txt'\n",
    "    test_file = f'negative_samples.txt'\n",
    "\n",
    "    item_count = defaultdict(int)\n",
    "    user_items = defaultdict()\n",
    "\n",
    "    lines = open('./{}/'.format(data_name) + data_file).readlines()\n",
    "    for line in lines:\n",
    "        user, items = line.strip().split(' ', 1)\n",
    "        items = items.split(' ')\n",
    "        items = [int(item) for item in items]\n",
    "        user_items[user] = items\n",
    "        for item in items:\n",
    "            item_count[item] += 1\n",
    "\n",
    "    all_item = list(item_count.keys())\n",
    "    count = list(item_count.values())\n",
    "    sum_value = np.sum([x for x in count])\n",
    "    probability = [value / sum_value for value in count]\n",
    "\n",
    "    user_neg_items = defaultdict()\n",
    "\n",
    "    for user, user_seq in user_items.items():\n",
    "        test_samples = []\n",
    "        while len(test_samples) < test_num:\n",
    "            if sample_type == 'random':\n",
    "                sample_ids = np.random.choice(all_item, test_num, replace=False)\n",
    "            else: # sample_type == 'pop':\n",
    "                sample_ids = np.random.choice(all_item, test_num, replace=False, p=probability)\n",
    "            sample_ids = [str(item) for item in sample_ids if item not in user_seq and item not in test_samples]\n",
    "            test_samples.extend(sample_ids)\n",
    "        test_samples = test_samples[:test_num]\n",
    "        user_neg_items[user] = test_samples\n",
    "\n",
    "    with open('./{}/'.format(data_name) + test_file, 'w') as out:\n",
    "        for user, samples in user_neg_items.items():\n",
    "            out.write(user+' '+' '.join(samples)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_data(short_data_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Splits for Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamaps = load_json(\"./{}/datamaps.json\".format(short_data_name))\n",
    "print(datamaps.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = []\n",
    "for review in parse(\"./raw_data/reviews_{}_5.json.gz\".format(full_data_name)):\n",
    "    review_data.append(review)\n",
    "print(len(review_data))\n",
    "print(review_data[0])\n",
    "\n",
    "raw_explanations = load_pickle('./raw_data/reviews_{}.pickle'.format(full_data_name))\n",
    "print(len(raw_explanations))\n",
    "print(raw_explanations[0])\n",
    "\n",
    "print(len(datamaps['user2id']))\n",
    "print(len(datamaps['item2id']))\n",
    "sparsity = 100.0 * len(review_data) / (len(datamaps['user2id']) * len(datamaps['item2id'])) \n",
    "print('sparsity: ', sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_review_indices = []\n",
    "for i in tqdm(range(len(review_data))):\n",
    "    if review_data[i]['reviewerID'] in datamaps['user2id'] and review_data[i]['asin'] in datamaps['item2id']:\n",
    "        valid_review_indices.append(i)\n",
    "print(len(valid_review_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_review_data = []\n",
    "no_sentence = 0\n",
    "for i in range(len(review_data)):\n",
    "    rev_ = review_data[i]\n",
    "    exp_ = raw_explanations[i]\n",
    "    assert rev_['reviewerID'] == exp_['user']\n",
    "    assert rev_['asin'] == exp_['item']\n",
    "    if 'sentence' in exp_:\n",
    "        list_len = len(exp_['sentence'])\n",
    "        selected_idx = random.randint(0, list_len-1)\n",
    "        rev_['explanation'] = exp_['sentence'][selected_idx][2]\n",
    "        rev_['feature'] = exp_['sentence'][selected_idx][0]   # add a random, or list all possible sentences\n",
    "    else:\n",
    "        no_sentence += 1\n",
    "    combined_review_data.append(rev_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_review_data[16]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata for Users & Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id2name = {}\n",
    "for i in range(len(combined_review_data)):\n",
    "    user_id = datamaps['user2id'][combined_review_data[i]['reviewerID']]\n",
    "    if 'reviewerName' in combined_review_data[i]:\n",
    "        user_id2name[user_id] = combined_review_data[i]['reviewerName']\n",
    "    else:\n",
    "        user_id2name[user_id] = combined_review_data[i]['reviewerID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(user_id2name, '{}/user_id2name.pkl'.format(short_data_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train/Val/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = len(review_data)\n",
    "print(population)\n",
    "data = range(population)\n",
    "\n",
    "user_mention_dict = {}\n",
    "item_mention_dict = {}\n",
    "for i in data:\n",
    "    review_datum = review_data[i]\n",
    "    user_ = review_datum['reviewerID']\n",
    "    item_ = review_datum['asin']\n",
    "    if user_ not in user_mention_dict:\n",
    "        user_mention_dict[user_] = [i]\n",
    "    else:\n",
    "        user_mention_dict[user_].append(i)\n",
    "    if item_ not in item_mention_dict:\n",
    "        item_mention_dict[item_] = [i]\n",
    "    else:\n",
    "        item_mention_dict[item_].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = []\n",
    "for u in tqdm(user_mention_dict.keys()):\n",
    "    index_cand = user_mention_dict[u]\n",
    "    random_choice = random.randint(0, len(index_cand)-1)\n",
    "    if index_cand[random_choice] not in train_indices:\n",
    "        train_indices.append(index_cand[random_choice])\n",
    "for it in tqdm(item_mention_dict.keys()):\n",
    "    index_cand = item_mention_dict[it]\n",
    "    random_choice = random.randint(0, len(index_cand)-1)\n",
    "    if index_cand[random_choice] not in train_indices:\n",
    "        train_indices.append(index_cand[random_choice])\n",
    "print(len(train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_indices = list(set(range(population)).difference(set(train_indices))) # in population but not in train_indices\n",
    "        \n",
    "print(len(remaining_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_indices = random.sample(range(len(remaining_indices)), round(population * 0.8) - len(train_indices))\n",
    "print(len(sub_indices))\n",
    "\n",
    "final_train_indices = list(set(np.array(remaining_indices)[sub_indices]).union(set(train_indices)))\n",
    "print(len(final_train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_indices = list(set(range(population)).difference(set(final_train_indices)))\n",
    "print(len(val_test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sub_indices = random.sample(range(len(val_test_indices)), round(population * 0.1))\n",
    "\n",
    "val_indices = list(np.array(val_test_indices)[sub_sub_indices])\n",
    "test_indices = list(set(val_test_indices).difference(set(val_indices)))\n",
    "print(len(val_indices))\n",
    "print(len(test_indices))\n",
    "\n",
    "all_indices = final_train_indices + val_indices + test_indices\n",
    "print(len(set(all_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_review_data = []\n",
    "for i in final_train_indices:\n",
    "    train_review_data.append(combined_review_data[i])\n",
    "    \n",
    "val_review_data = []\n",
    "for j in val_indices:\n",
    "    val_review_data.append(combined_review_data[j])\n",
    "    \n",
    "test_review_data = []\n",
    "for k in test_indices:\n",
    "    test_review_data.append(combined_review_data[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {'train': train_review_data,\n",
    "           'val': val_review_data,\n",
    "           'test': test_review_data,\n",
    "           'train_indices': final_train_indices,\n",
    "           'val_indices': val_indices,\n",
    "           'test_indices': test_indices\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(outputs, './{}/review_splits.pkl'.format(short_data_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_review_data[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exp_data = []\n",
    "for i in final_train_indices:\n",
    "    if 'explanation' in combined_review_data[i]:\n",
    "        train_exp_data.append(combined_review_data[i])\n",
    "        \n",
    "val_exp_data = []\n",
    "for j in val_indices:\n",
    "    if 'explanation' in combined_review_data[j]:\n",
    "        val_exp_data.append(combined_review_data[j])\n",
    "\n",
    "test_exp_data = []\n",
    "for k in test_indices:\n",
    "    if 'explanation' in combined_review_data[k]:\n",
    "        test_exp_data.append(combined_review_data[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {'train': train_exp_data,\n",
    "           'val': val_exp_data,\n",
    "           'test': test_exp_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(outputs, './{}/exp_splits.pkl'.format(short_data_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exp_data[6]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-balancing Training Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits = load_pickle('./{}/review_splits.pkl'.format(short_data_name))\n",
    "train_review_data = data_splits['train']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation of Minority Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {float(r): 0 for r in range(1,6)}\n",
    "for record in train_review_data:\n",
    "    counts[record['overall']] += 1\n",
    "T = sum(counts.values())\n",
    "print(T)\n",
    "for k,c in counts.items():\n",
    "    counts[k] = float(counts[k])/T\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "X = [float(r) for r in range(1,6)]\n",
    "plt.bar(X, [counts[x] for x in X])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(1, 0, -0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How should each class augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_prob = {r: max(1.0 / (len(counts)-1) - c,0.) for r,c in counts.items()}\n",
    "print(augment_prob)\n",
    "sum_P = sum(augment_prob.values())\n",
    "print(sum_P)\n",
    "all_ratings = [float(r) for r in range(1,6)]\n",
    "augment_multiplier = {r: augment_prob[r] / (sum_P * counts[r]) for r in all_ratings}\n",
    "print(augment_multiplier)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Augment with variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dist_to_prob = [0.5,0.1,0.03,0.01,0.003]\n",
    "rating_perturbation_prob = {}\n",
    "for r in all_ratings:\n",
    "    P = np.array([dist_to_prob[int(abs(r - r_2))] for r_2 in all_ratings])\n",
    "    P /= np.sum(P)\n",
    "    rating_perturbation_prob[r] = P\n",
    "print(rating_perturbation_prob)\n",
    "augmented_counts = {r: 0 for r in all_ratings}\n",
    "augmented_records = []\n",
    "for record in train_review_data:\n",
    "    record_rating = record['overall']\n",
    "    M = augment_multiplier[record_rating]\n",
    "    remainder = M % 1\n",
    "    M = int(M)+1 if np.random.random() < remainder else int(M)\n",
    "    sample_amount = np.random.multinomial(M, rating_perturbation_prob[record_rating])\n",
    "    for i,n_sample in enumerate(sample_amount):\n",
    "        for j in range(n_sample):\n",
    "            new_record = {k:v for k,v in record.items()}\n",
    "            new_record['overall'] = float(i+1)\n",
    "            augmented_records.append(new_record)\n",
    "        augmented_counts[float(i+1)] += n_sample\n",
    "print(augmented_counts)\n",
    "print(len(augmented_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits['train'] = data_splits['train'] + augmented_records\n",
    "print(len(data_splits['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(data_splits, './{}/rating_splits_augmented.pkl'.format(short_data_name)) # for rating"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. New counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_review_data = data_splits['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {float(r): 0 for r in range(1,6)}\n",
    "for record in train_review_data:\n",
    "    counts[record['overall']] += 1\n",
    "T = sum(counts.values())\n",
    "print(T)\n",
    "for k,c in counts.items():\n",
    "    counts[k] = float(counts[k])/T\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "X = [float(r) for r in range(1,6)]\n",
    "plt.bar(X, [counts[x] for x in X])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p5a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

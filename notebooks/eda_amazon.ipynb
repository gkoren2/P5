{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def save_pickle(data, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def ReadLineFromFile(path):\n",
    "    lines = []\n",
    "    with open(path,'r') as fd:\n",
    "        for line in fd:\n",
    "            lines.append(line.rstrip('\\n'))\n",
    "    return lines\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "        \n",
    "'''\n",
    "Set seeds\n",
    "'''\n",
    "seed = 2022\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_data_name = 'beauty'\n",
    "os.mkdir(short_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if short_data_name == 'beauty':\n",
    "    full_data_name = 'Beauty'\n",
    "elif short_data_name == 'toys':\n",
    "    full_data_name = 'Toys_and_Games'\n",
    "elif short_data_name == 'sports':\n",
    "    full_data_name = 'Sports_and_Outdoors'\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Sequential Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return (user item timestamp) sort in get_interaction\n",
    "def Amazon(dataset_name, rating_score):\n",
    "    '''\n",
    "    reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "    asin - ID of the product, e.g. 0000013714\n",
    "    reviewerName - name of the reviewer\n",
    "    helpful - helpfulness rating of the review, e.g. 2/3\n",
    "    --\"helpful\": [2, 3],\n",
    "    reviewText - text of the review\n",
    "    --\"reviewText\": \"I bought this for my husband who plays the piano. ...\"\n",
    "    overall - rating of the product\n",
    "    --\"overall\": 5.0,\n",
    "    summary - summary of the review\n",
    "    --\"summary\": \"Heavenly Highway Hymns\",\n",
    "    unixReviewTime - time of the review (unix time)\n",
    "    --\"unixReviewTime\": 1252800000,\n",
    "    reviewTime - time of the review (raw)\n",
    "    --\"reviewTime\": \"09 13, 2009\"\n",
    "    '''\n",
    "    datas = []\n",
    "    # older Amazon\n",
    "    data_file = './raw_data/reviews_' + dataset_name + '.json.gz'\n",
    "    # latest Amazon\n",
    "    # data_file = '/home/hui_wang/data/new_Amazon/' + dataset_name + '.json.gz'\n",
    "    for inter in parse(data_file):\n",
    "        if float(inter['overall']) <= rating_score: # 小于一定分数去掉\n",
    "            continue\n",
    "        user = inter['reviewerID']\n",
    "        item = inter['asin']\n",
    "        time = inter['unixReviewTime']\n",
    "        datas.append((user, item, int(time)))\n",
    "    return datas\n",
    "\n",
    "def Amazon_meta(dataset_name, data_maps):\n",
    "    '''\n",
    "    asin - ID of the product, e.g. 0000031852\n",
    "    --\"asin\": \"0000031852\",\n",
    "    title - name of the product\n",
    "    --\"title\": \"Girls Ballet Tutu Zebra Hot Pink\",\n",
    "    description\n",
    "    price - price in US dollars (at time of crawl)\n",
    "    --\"price\": 3.17,\n",
    "    imUrl - url of the product image (str)\n",
    "    --\"imUrl\": \"http://ecx.images-amazon.com/images/I/51fAmVkTbyL._SY300_.jpg\",\n",
    "    related - related products (also bought, also viewed, bought together, buy after viewing)\n",
    "    --\"related\":{\n",
    "        \"also_bought\": [\"B00JHONN1S\"],\n",
    "        \"also_viewed\": [\"B002BZX8Z6\"],\n",
    "        \"bought_together\": [\"B002BZX8Z6\"]\n",
    "    },\n",
    "    salesRank - sales rank information\n",
    "    --\"salesRank\": {\"Toys & Games\": 211836}\n",
    "    brand - brand name\n",
    "    --\"brand\": \"Coxlures\",\n",
    "    categories - list of categories the product belongs to\n",
    "    --\"categories\": [[\"Sports & Outdoors\", \"Other Sports\", \"Dance\"]]\n",
    "    '''\n",
    "    datas = {}\n",
    "    meta_file = './raw_data/meta_' + dataset_name + '.json.gz'\n",
    "    item_asins = list(data_maps['item2id'].keys())\n",
    "    for info in parse(meta_file):\n",
    "        if info['asin'] not in item_asins:\n",
    "            continue\n",
    "        datas[info['asin']] = info\n",
    "    return datas\n",
    "\n",
    "def add_comma(num):\n",
    "    # 1000000 -> 1,000,000\n",
    "    str_num = str(num)\n",
    "    res_num = ''\n",
    "    for i in range(len(str_num)):\n",
    "        res_num += str_num[i]\n",
    "        if (len(str_num)-i-1) % 3 == 0:\n",
    "            res_num += ','\n",
    "    return res_num[:-1]\n",
    "\n",
    "# categories 和 brand is all attribute\n",
    "def get_attribute_Amazon(meta_infos, datamaps, attribute_core):\n",
    "\n",
    "    attributes = defaultdict(int)\n",
    "    for iid, info in tqdm(meta_infos.items()):\n",
    "        for cates in info['categories']:\n",
    "            for cate in cates[1:]: # 把主类删除 没有用\n",
    "                attributes[cate] +=1\n",
    "        try:\n",
    "            attributes[info['brand']] += 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    print(f'before delete, attribute num:{len(attributes)}')\n",
    "    new_meta = {}\n",
    "    for iid, info in tqdm(meta_infos.items()):\n",
    "        new_meta[iid] = []\n",
    "\n",
    "        try:\n",
    "            if attributes[info['brand']] >= attribute_core:\n",
    "                new_meta[iid].append(info['brand'])\n",
    "        except:\n",
    "            pass\n",
    "        for cates in info['categories']:\n",
    "            for cate in cates[1:]:\n",
    "                if attributes[cate] >= attribute_core:\n",
    "                    new_meta[iid].append(cate)\n",
    "    # 做映射\n",
    "    attribute2id = {}\n",
    "    id2attribute = {}\n",
    "    attributeid2num = defaultdict(int)\n",
    "    attribute_id = 1\n",
    "    items2attributes = {}\n",
    "    attribute_lens = []\n",
    "\n",
    "    for iid, attributes in new_meta.items():\n",
    "        item_id = datamaps['item2id'][iid]\n",
    "        items2attributes[item_id] = []\n",
    "        for attribute in attributes:\n",
    "            if attribute not in attribute2id:\n",
    "                attribute2id[attribute] = attribute_id\n",
    "                id2attribute[attribute_id] = attribute\n",
    "                attribute_id += 1\n",
    "            attributeid2num[attribute2id[attribute]] += 1\n",
    "            items2attributes[item_id].append(attribute2id[attribute])\n",
    "        attribute_lens.append(len(items2attributes[item_id]))\n",
    "    print(f'before delete, attribute num:{len(attribute2id)}')\n",
    "    print(f'attributes len, Min:{np.min(attribute_lens)}, Max:{np.max(attribute_lens)}, Avg.:{np.mean(attribute_lens):.4f}')\n",
    "    # 更新datamap\n",
    "    datamaps['attribute2id'] = attribute2id\n",
    "    datamaps['id2attribute'] = id2attribute\n",
    "    datamaps['attributeid2num'] = attributeid2num\n",
    "    return len(attribute2id), np.mean(attribute_lens), datamaps, items2attributes\n",
    "\n",
    "\n",
    "def get_interaction(datas):\n",
    "    user_seq = {}\n",
    "    for data in datas:\n",
    "        user, item, time = data\n",
    "        if user in user_seq:\n",
    "            user_seq[user].append((item, time))\n",
    "        else:\n",
    "            user_seq[user] = []\n",
    "            user_seq[user].append((item, time))\n",
    "\n",
    "    for user, item_time in user_seq.items():\n",
    "        item_time.sort(key=lambda x: x[1])  # sort each dataset individually\n",
    "        items = []\n",
    "        for t in item_time:\n",
    "            items.append(t[0])\n",
    "        user_seq[user] = items\n",
    "    return user_seq\n",
    "\n",
    "# K-core user_core item_core\n",
    "def check_Kcore(user_items, user_core, item_core):\n",
    "    user_count = defaultdict(int)\n",
    "    item_count = defaultdict(int)\n",
    "    for user, items in user_items.items():\n",
    "        for item in items:\n",
    "            user_count[user] += 1\n",
    "            item_count[item] += 1\n",
    "\n",
    "    for user, num in user_count.items():\n",
    "        if num < user_core:\n",
    "            return user_count, item_count, False\n",
    "    for item, num in item_count.items():\n",
    "        if num < item_core:\n",
    "            return user_count, item_count, False\n",
    "    return user_count, item_count, True # 已经保证Kcore\n",
    "\n",
    "# 循环过滤 K-core\n",
    "def filter_Kcore(user_items, user_core, item_core): # user 接所有items\n",
    "    user_count, item_count, isKcore = check_Kcore(user_items, user_core, item_core)\n",
    "    while not isKcore:\n",
    "        for user, num in user_count.items():\n",
    "            if user_count[user] < user_core: # 直接把user 删除\n",
    "                user_items.pop(user)\n",
    "            else:\n",
    "                for item in user_items[user]:\n",
    "                    if item_count[item] < item_core:\n",
    "                        user_items[user].remove(item)\n",
    "        user_count, item_count, isKcore = check_Kcore(user_items, user_core, item_core)\n",
    "    return user_items\n",
    "\n",
    "def id_map(user_items): # user_items dict\n",
    "    user2id = {} # raw 2 uid\n",
    "    item2id = {} # raw 2 iid\n",
    "    id2user = {} # uid 2 raw\n",
    "    id2item = {} # iid 2 raw\n",
    "    user_id = 1\n",
    "    item_id = 1\n",
    "    final_data = {}\n",
    "    random_user_list = list(user_items.keys())\n",
    "    random.shuffle(random_user_list)\n",
    "    for user in random_user_list:\n",
    "        items = user_items[user]\n",
    "        if user not in user2id:\n",
    "            user2id[user] = str(user_id)\n",
    "            id2user[str(user_id)] = user\n",
    "            user_id += 1\n",
    "        iids = [] # item id lists\n",
    "        for item in items:\n",
    "            if item not in item2id:\n",
    "                item2id[item] = str(item_id)\n",
    "                id2item[str(item_id)] = item\n",
    "                item_id += 1\n",
    "            iids.append(item2id[item])\n",
    "        uid = user2id[user]\n",
    "        final_data[uid] = iids\n",
    "    data_maps = {\n",
    "        'user2id': user2id,\n",
    "        'item2id': item2id,\n",
    "        'id2user': id2user,\n",
    "        'id2item': id2item\n",
    "    }\n",
    "    return final_data, user_id-1, item_id-1, data_maps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_name, acronym, data_type='Amazon'):\n",
    "    assert data_type in {'Amazon', 'Yelp'}\n",
    "    rating_score = 0.0  # rating score smaller than this score would be deleted\n",
    "    # user 5-core item 5-core\n",
    "    user_core = 5\n",
    "    item_core = 5\n",
    "    attribute_core = 0\n",
    "\n",
    "    if data_type == 'Yelp':\n",
    "        date_max = '2019-12-31 00:00:00'\n",
    "        date_min = '2019-01-01 00:00:00'\n",
    "        datas = Yelp(date_min, date_max, rating_score)\n",
    "    else:\n",
    "        datas = Amazon(data_name+'_5', rating_score=rating_score)\n",
    "\n",
    "    user_items = get_interaction(datas)\n",
    "    print(f'{data_name} Raw data has been processed! Lower than {rating_score} are deleted!')\n",
    "    # raw_id user: [item1, item2, item3...]\n",
    "    user_items = filter_Kcore(user_items, user_core=user_core, item_core=item_core)\n",
    "    print(f'User {user_core}-core complete! Item {item_core}-core complete!')\n",
    "\n",
    "    user_items, user_num, item_num, data_maps = id_map(user_items)\n",
    "    user_count, item_count, _ = check_Kcore(user_items, user_core=user_core, item_core=item_core)\n",
    "    user_count_list = list(user_count.values())\n",
    "    user_avg, user_min, user_max = np.mean(user_count_list), np.min(user_count_list), np.max(user_count_list)\n",
    "    item_count_list = list(item_count.values())\n",
    "    item_avg, item_min, item_max = np.mean(item_count_list), np.min(item_count_list), np.max(item_count_list)\n",
    "    interact_num = np.sum([x for x in user_count_list])\n",
    "    sparsity = (1 - interact_num / (user_num * item_num)) * 100\n",
    "    show_info = f'Total User: {user_num}, Avg User: {user_avg:.4f}, Min Len: {user_min}, Max Len: {user_max}\\n' + \\\n",
    "                f'Total Item: {item_num}, Avg Item: {item_avg:.4f}, Min Inter: {item_min}, Max Inter: {item_max}\\n' + \\\n",
    "                f'Iteraction Num: {interact_num}, Sparsity: {sparsity:.2f}%'\n",
    "    print(show_info)\n",
    "\n",
    "\n",
    "    print('Begin extracting meta infos...')\n",
    "\n",
    "    if data_type == 'Amazon':\n",
    "        meta_infos = Amazon_meta(data_name, data_maps)\n",
    "        attribute_num, avg_attribute, datamaps, item2attributes = get_attribute_Amazon(meta_infos, data_maps, attribute_core)\n",
    "    else:\n",
    "        meta_infos = Yelp_meta(data_maps)\n",
    "        attribute_num, avg_attribute, datamaps, item2attributes = get_attribute_Yelp(meta_infos, data_maps, attribute_core)\n",
    "\n",
    "    print(f'{data_name} & {add_comma(user_num)}& {add_comma(item_num)} & {user_avg:.1f}'\n",
    "          f'& {item_avg:.1f}& {add_comma(interact_num)}& {sparsity:.2f}\\%&{add_comma(attribute_num)}&'\n",
    "          f'{avg_attribute:.1f} \\\\')\n",
    "\n",
    "    # -------------- Save Data ---------------\n",
    "    data_file = './{}/'.format(acronym) + 'sequential_data.txt'\n",
    "    item2attributes_file = './{}/'.format(acronym) + 'item2attributes.json'\n",
    "    datamaps_file = './{}/'.format(acronym) + 'datamaps.json'\n",
    "\n",
    "    with open(data_file, 'w') as out:\n",
    "        for user, items in user_items.items():\n",
    "            out.write(user + ' ' + ' '.join(items) + '\\n')\n",
    "    json_str = json.dumps(item2attributes)\n",
    "    with open(item2attributes_file, 'w') as out:\n",
    "        out.write(json_str)\n",
    "        \n",
    "    json_str = json.dumps(datamaps)\n",
    "    with open(datamaps_file, 'w') as out:\n",
    "        out.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(full_data_name, short_data_name, data_type='Amazon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_test_data(data_name, test_num=99, sample_type='random'):\n",
    "    \"\"\"\n",
    "    sample_type:\n",
    "        random:  sample `test_num` negative items randomly.\n",
    "        pop: sample `test_num` negative items according to item popularity.\n",
    "    \"\"\"\n",
    "\n",
    "    data_file = f'sequential_data.txt'\n",
    "    test_file = f'negative_samples.txt'\n",
    "\n",
    "    item_count = defaultdict(int)\n",
    "    user_items = defaultdict()\n",
    "\n",
    "    lines = open('./{}/'.format(data_name) + data_file).readlines()\n",
    "    for line in lines:\n",
    "        user, items = line.strip().split(' ', 1)\n",
    "        items = items.split(' ')\n",
    "        items = [int(item) for item in items]\n",
    "        user_items[user] = items\n",
    "        for item in items:\n",
    "            item_count[item] += 1\n",
    "\n",
    "    all_item = list(item_count.keys())\n",
    "    count = list(item_count.values())\n",
    "    sum_value = np.sum([x for x in count])\n",
    "    probability = [value / sum_value for value in count]\n",
    "\n",
    "    user_neg_items = defaultdict()\n",
    "\n",
    "    for user, user_seq in user_items.items():\n",
    "        test_samples = []\n",
    "        while len(test_samples) < test_num:\n",
    "            if sample_type == 'random':\n",
    "                sample_ids = np.random.choice(all_item, test_num, replace=False)\n",
    "            else: # sample_type == 'pop':\n",
    "                sample_ids = np.random.choice(all_item, test_num, replace=False, p=probability)\n",
    "            sample_ids = [str(item) for item in sample_ids if item not in user_seq and item not in test_samples]\n",
    "            test_samples.extend(sample_ids)\n",
    "        test_samples = test_samples[:test_num]\n",
    "        user_neg_items[user] = test_samples\n",
    "\n",
    "    with open('./{}/'.format(data_name) + test_file, 'w') as out:\n",
    "        for user, samples in user_neg_items.items():\n",
    "            out.write(user+' '+' '.join(samples)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_data(short_data_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Splits for Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamaps = load_json(\"./{}/datamaps.json\".format(short_data_name))\n",
    "print(datamaps.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = []\n",
    "for review in parse(\"./raw_data/reviews_{}_5.json.gz\".format(full_data_name)):\n",
    "    review_data.append(review)\n",
    "print(len(review_data))\n",
    "print(review_data[0])\n",
    "\n",
    "raw_explanations = load_pickle('./raw_data/reviews_{}.pickle'.format(full_data_name))\n",
    "print(len(raw_explanations))\n",
    "print(raw_explanations[0])\n",
    "\n",
    "print(len(datamaps['user2id']))\n",
    "print(len(datamaps['item2id']))\n",
    "sparsity = 100.0 * len(review_data) / (len(datamaps['user2id']) * len(datamaps['item2id'])) \n",
    "print('sparsity: ', sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_review_indices = []\n",
    "for i in tqdm(range(len(review_data))):\n",
    "    if review_data[i]['reviewerID'] in datamaps['user2id'] and review_data[i]['asin'] in datamaps['item2id']:\n",
    "        valid_review_indices.append(i)\n",
    "print(len(valid_review_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_review_data = []\n",
    "no_sentence = 0\n",
    "for i in range(len(review_data)):\n",
    "    rev_ = review_data[i]\n",
    "    exp_ = raw_explanations[i]\n",
    "    assert rev_['reviewerID'] == exp_['user']\n",
    "    assert rev_['asin'] == exp_['item']\n",
    "    if 'sentence' in exp_:\n",
    "        list_len = len(exp_['sentence'])\n",
    "        selected_idx = random.randint(0, list_len-1)\n",
    "        rev_['explanation'] = exp_['sentence'][selected_idx][2]\n",
    "        rev_['feature'] = exp_['sentence'][selected_idx][0]   # add a random, or list all possible sentences\n",
    "    else:\n",
    "        no_sentence += 1\n",
    "    combined_review_data.append(rev_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_review_data[16]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata for Users & Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id2name = {}\n",
    "for i in range(len(combined_review_data)):\n",
    "    user_id = datamaps['user2id'][combined_review_data[i]['reviewerID']]\n",
    "    if 'reviewerName' in combined_review_data[i]:\n",
    "        user_id2name[user_id] = combined_review_data[i]['reviewerName']\n",
    "    else:\n",
    "        user_id2name[user_id] = combined_review_data[i]['reviewerID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(user_id2name, '{}/user_id2name.pkl'.format(short_data_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train/Val/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = len(review_data)\n",
    "print(population)\n",
    "data = range(population)\n",
    "\n",
    "user_mention_dict = {}\n",
    "item_mention_dict = {}\n",
    "for i in data:\n",
    "    review_datum = review_data[i]\n",
    "    user_ = review_datum['reviewerID']\n",
    "    item_ = review_datum['asin']\n",
    "    if user_ not in user_mention_dict:\n",
    "        user_mention_dict[user_] = [i]\n",
    "    else:\n",
    "        user_mention_dict[user_].append(i)\n",
    "    if item_ not in item_mention_dict:\n",
    "        item_mention_dict[item_] = [i]\n",
    "    else:\n",
    "        item_mention_dict[item_].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = []\n",
    "for u in tqdm(user_mention_dict.keys()):\n",
    "    index_cand = user_mention_dict[u]\n",
    "    random_choice = random.randint(0, len(index_cand)-1)\n",
    "    if index_cand[random_choice] not in train_indices:\n",
    "        train_indices.append(index_cand[random_choice])\n",
    "for it in tqdm(item_mention_dict.keys()):\n",
    "    index_cand = item_mention_dict[it]\n",
    "    random_choice = random.randint(0, len(index_cand)-1)\n",
    "    if index_cand[random_choice] not in train_indices:\n",
    "        train_indices.append(index_cand[random_choice])\n",
    "print(len(train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_indices = list(set(range(population)).difference(set(train_indices))) # in population but not in train_indices\n",
    "        \n",
    "print(len(remaining_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_indices = random.sample(range(len(remaining_indices)), round(population * 0.8) - len(train_indices))\n",
    "print(len(sub_indices))\n",
    "\n",
    "final_train_indices = list(set(np.array(remaining_indices)[sub_indices]).union(set(train_indices)))\n",
    "print(len(final_train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_indices = list(set(range(population)).difference(set(final_train_indices)))\n",
    "print(len(val_test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sub_indices = random.sample(range(len(val_test_indices)), round(population * 0.1))\n",
    "\n",
    "val_indices = list(np.array(val_test_indices)[sub_sub_indices])\n",
    "test_indices = list(set(val_test_indices).difference(set(val_indices)))\n",
    "print(len(val_indices))\n",
    "print(len(test_indices))\n",
    "\n",
    "all_indices = final_train_indices + val_indices + test_indices\n",
    "print(len(set(all_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_review_data = []\n",
    "for i in final_train_indices:\n",
    "    train_review_data.append(combined_review_data[i])\n",
    "    \n",
    "val_review_data = []\n",
    "for j in val_indices:\n",
    "    val_review_data.append(combined_review_data[j])\n",
    "    \n",
    "test_review_data = []\n",
    "for k in test_indices:\n",
    "    test_review_data.append(combined_review_data[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {'train': train_review_data,\n",
    "           'val': val_review_data,\n",
    "           'test': test_review_data,\n",
    "           'train_indices': final_train_indices,\n",
    "           'val_indices': val_indices,\n",
    "           'test_indices': test_indices\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(outputs, './{}/review_splits.pkl'.format(short_data_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_review_data[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exp_data = []\n",
    "for i in final_train_indices:\n",
    "    if 'explanation' in combined_review_data[i]:\n",
    "        train_exp_data.append(combined_review_data[i])\n",
    "        \n",
    "val_exp_data = []\n",
    "for j in val_indices:\n",
    "    if 'explanation' in combined_review_data[j]:\n",
    "        val_exp_data.append(combined_review_data[j])\n",
    "\n",
    "test_exp_data = []\n",
    "for k in test_indices:\n",
    "    if 'explanation' in combined_review_data[k]:\n",
    "        test_exp_data.append(combined_review_data[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {'train': train_exp_data,\n",
    "           'val': val_exp_data,\n",
    "           'test': test_exp_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(outputs, './{}/exp_splits.pkl'.format(short_data_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exp_data[6]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-balancing Training Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits = load_pickle('./{}/review_splits.pkl'.format(short_data_name))\n",
    "train_review_data = data_splits['train']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation of Minority Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {float(r): 0 for r in range(1,6)}\n",
    "for record in train_review_data:\n",
    "    counts[record['overall']] += 1\n",
    "T = sum(counts.values())\n",
    "print(T)\n",
    "for k,c in counts.items():\n",
    "    counts[k] = float(counts[k])/T\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "X = [float(r) for r in range(1,6)]\n",
    "plt.bar(X, [counts[x] for x in X])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(1, 0, -0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How should each class augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_prob = {r: max(1.0 / (len(counts)-1) - c,0.) for r,c in counts.items()}\n",
    "print(augment_prob)\n",
    "sum_P = sum(augment_prob.values())\n",
    "print(sum_P)\n",
    "all_ratings = [float(r) for r in range(1,6)]\n",
    "augment_multiplier = {r: augment_prob[r] / (sum_P * counts[r]) for r in all_ratings}\n",
    "print(augment_multiplier)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Augment with variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dist_to_prob = [0.5,0.1,0.03,0.01,0.003]\n",
    "rating_perturbation_prob = {}\n",
    "for r in all_ratings:\n",
    "    P = np.array([dist_to_prob[int(abs(r - r_2))] for r_2 in all_ratings])\n",
    "    P /= np.sum(P)\n",
    "    rating_perturbation_prob[r] = P\n",
    "print(rating_perturbation_prob)\n",
    "augmented_counts = {r: 0 for r in all_ratings}\n",
    "augmented_records = []\n",
    "for record in train_review_data:\n",
    "    record_rating = record['overall']\n",
    "    M = augment_multiplier[record_rating]\n",
    "    remainder = M % 1\n",
    "    M = int(M)+1 if np.random.random() < remainder else int(M)\n",
    "    sample_amount = np.random.multinomial(M, rating_perturbation_prob[record_rating])\n",
    "    for i,n_sample in enumerate(sample_amount):\n",
    "        for j in range(n_sample):\n",
    "            new_record = {k:v for k,v in record.items()}\n",
    "            new_record['overall'] = float(i+1)\n",
    "            augmented_records.append(new_record)\n",
    "        augmented_counts[float(i+1)] += n_sample\n",
    "print(augmented_counts)\n",
    "print(len(augmented_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits['train'] = data_splits['train'] + augmented_records\n",
    "print(len(data_splits['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(data_splits, './{}/rating_splits_augmented.pkl'.format(short_data_name)) # for rating"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. New counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_review_data = data_splits['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {float(r): 0 for r in range(1,6)}\n",
    "for record in train_review_data:\n",
    "    counts[record['overall']] += 1\n",
    "T = sum(counts.values())\n",
    "print(T)\n",
    "for k,c in counts.items():\n",
    "    counts[k] = float(counts[k])/T\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "X = [float(r) for r in range(1,6)]\n",
    "plt.bar(X, [counts[x] for x in X])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p5a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
